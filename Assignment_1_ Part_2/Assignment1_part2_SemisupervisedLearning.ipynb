{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1_part2_SemisupervisedLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/AdvanceDeeplearning-CMPE-297/blob/master/Assignment_1_%20Part_2/Assignment1_part2_SemisupervisedLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgVIJQ3ZncLj",
        "colab_type": "text"
      },
      "source": [
        "# Semi Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tw5V7Avp0qo",
        "colab_type": "text"
      },
      "source": [
        "# Implementation Details and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jb4U8Oep_Xu",
        "colab_type": "text"
      },
      "source": [
        "**Semi-supervised** is an machine learning approach that deals with both label and unlabeled data. The amount of labeled data is very less compared to unlabeled data. So Semi-supervised learning belongs to both unsupervised and supervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEUa4e3SqZAx",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Semi supervised learning methods actually use the unlabeled data to modify or to change the priority of the data obtained from labeled data. Some methods are probabilistics also. We get a joint distribution for that.  Original discriminative methods can not be used here for semi supervised problems.\n",
        "\n",
        "\n",
        "As mentioned above, semi supervised learning is a combination of supervised and unsupervised. So at first I loaded the Mnist. It is a labeled data. I have taken 20% of the labeled data. For the rest of the 80% data, I have removed the label and made it ready for unsupervised. Assigned label -1 for that. Finally I have defined the network, trained the model. This model performs with 92% accuracy. The last section visualizes the prediction of the model. \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4NeUOswqdzq",
        "colab_type": "text"
      },
      "source": [
        "# Using Mnist Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFF9dBg6JRgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import pickle \n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from scipy import ndimage\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "import torchvision\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK_B6gVuSwx1",
        "colab_type": "text"
      },
      "source": [
        "## Parameters Definition "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8NENnsqgfKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74542db7-56e5-4135-9a2a-a095e5a9b9ab"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f93786060c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl0qs02yqL3y",
        "colab_type": "text"
      },
      "source": [
        "## Load Mnist\n",
        "\n",
        "loading data and doing all the preprocessing stuffs here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjweFGp_x6dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6hnj8d9q-IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_dataset =  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ]))\n",
        "\n",
        "\n",
        "val_dataset = torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ]))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia9ZOu55ql4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff7a0a61-4414-44b9-f967-aa9ab9e67705"
      },
      "source": [
        "len(init_dataset)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02dUx8G5pFJb",
        "colab_type": "text"
      },
      "source": [
        "## Spliting data for semi-supervised [20% labeled + 80% unlabeled]\n",
        "\n",
        "Splitting the data to remove label for some data. Making the data prepared for semi supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8VAjfxLqQD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73b63ad7-6688-4107-8d3f-0a5cd5a4edcb"
      },
      "source": [
        "lengths = [int(len(init_dataset)*0.2), int(len(init_dataset)*0.8)]\n",
        "labeled_subsetA, unlabeled_subsetB = random_split(init_dataset, lengths)\n",
        "\n",
        "\n",
        "\n",
        "train_unlabeled_data = [(unlabeled_subsetB[i][0],-1) for i in range(len(unlabeled_subsetB))]\n",
        "len(train_unlabeled_data)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd8ZFm9Gt1F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loaders(train_labeled_data, train_unlabeled_data, test_data, train_batch_size, val_batch_size):\n",
        "    train_loader = DataLoader(train_labeled_data, batch_size=train_batch_size, shuffle=True)\n",
        "    train_unlabeled_loader = DataLoader(train_unlabeled_data, batch_size=train_batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(test_data, batch_size=val_batch_size, shuffle=False,)\n",
        "\n",
        "\n",
        "\n",
        "    return train_loader,train_unlabeled_loader, val_loader"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEhLAk4zu5fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "\n",
        "train_labeled_loader2,train_unlabeled_loader2,val_loader2 =  get_data_loaders(labeled_subsetA, train_unlabeled_data,val_dataset, batch_size_train, batch_size_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdq44oxRi-nD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "71cc2155-a9fd-4dea-e9f5-18eb7fb04f11"
      },
      "source": [
        "batch1 = next(iter(train_loader))\n",
        "print(batch1[0].shape)\n",
        "print(batch1[1].shape)\n",
        "len(batch1)\n",
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWflUktWouc5",
        "colab_type": "text"
      },
      "source": [
        "## Defing Network\n",
        "\n",
        "Following code are to define a network to train the model for semi supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwGo4gT_guI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8lcj0xsgxTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network = Net()\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXtiBjHPg0Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(val_loader2.dataset) for i in range(n_epochs + 1)]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLAEq0jAxvXN",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "Training code is implemented below with 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxe0HG4FwbnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cycles = 20\n",
        "# training\n",
        "def train2(epoch=10):\n",
        "    network.train()\n",
        "    \n",
        "    #pre-training without unlabeled data \n",
        "    if epoch > num_cycles:\n",
        "        for batch_idx, (data, target) in enumerate(train_unlabeled_loader2):\n",
        "            network.eval()\n",
        "            output = network(data)\n",
        "            fake_target = (output.data.max(1)[1].view(-1)) # using pseudo label method and get pseudo labels\n",
        "            network.train()\n",
        "            #data.volatile = False\n",
        "            optimizer.zero_grad()\n",
        "            output = network(data)\n",
        "            loss = F.nll_loss(output, fake_target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_idx % 10 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_unlabeled_loader2.dataset),\n",
        "                    100. * batch_idx / len(train_unlabeled_loader2), loss.item()))\n",
        "\n",
        "    avg_train_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_labeled_loader2):\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = network(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_labeled_loader2.dataset),\n",
        "                100. * batch_idx / len(train_labeled_loader2), loss.item()))\n",
        "            avg_train_loss += loss.item()\n",
        "            train_losses.append(loss.item())\n",
        "            train_counter.append(\n",
        "              (batch_idx*64) + ((epoch-1)*len(train_labeled_loader2.dataset)))\n",
        "     \n",
        "    avg_train_loss = avg_train_loss / (len(train_labeled_loader2) / 500)\n",
        "    #loss_compare.write(str(avg_train_loss) + ',') # no need for now\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVZPptpcg6dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in val_loader2: #modifing it : test_loader\n",
        "      output = network(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(val_loader2.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(val_loader2.dataset),\n",
        "    100. * correct / len(val_loader2.dataset)))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm49E6-m0RUZ",
        "colab_type": "text"
      },
      "source": [
        "## Network Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZLzdJBNg9RN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7fff8a9-14b7-4128-9646-32b768af8ef1"
      },
      "source": [
        "#test()-- don't use this\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train2(epoch)\n",
        "  test()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/12000 (0%)]\tLoss: 2.280108\n",
            "Train Epoch: 1 [640/12000 (5%)]\tLoss: 2.300120\n",
            "Train Epoch: 1 [1280/12000 (11%)]\tLoss: 2.315727\n",
            "Train Epoch: 1 [1920/12000 (16%)]\tLoss: 2.288256\n",
            "Train Epoch: 1 [2560/12000 (21%)]\tLoss: 2.262122\n",
            "Train Epoch: 1 [3200/12000 (27%)]\tLoss: 2.236043\n",
            "Train Epoch: 1 [3840/12000 (32%)]\tLoss: 2.240895\n",
            "Train Epoch: 1 [4480/12000 (37%)]\tLoss: 2.226709\n",
            "Train Epoch: 1 [5120/12000 (43%)]\tLoss: 2.216369\n",
            "Train Epoch: 1 [5760/12000 (48%)]\tLoss: 2.037981\n",
            "Train Epoch: 1 [6400/12000 (53%)]\tLoss: 2.044498\n",
            "Train Epoch: 1 [7040/12000 (59%)]\tLoss: 1.922124\n",
            "Train Epoch: 1 [7680/12000 (64%)]\tLoss: 1.860842\n",
            "Train Epoch: 1 [8320/12000 (69%)]\tLoss: 1.929248\n",
            "Train Epoch: 1 [8960/12000 (74%)]\tLoss: 1.859352\n",
            "Train Epoch: 1 [9600/12000 (80%)]\tLoss: 1.547276\n",
            "Train Epoch: 1 [10240/12000 (85%)]\tLoss: 1.469411\n",
            "Train Epoch: 1 [10880/12000 (90%)]\tLoss: 1.380514\n",
            "Train Epoch: 1 [11520/12000 (96%)]\tLoss: 1.304663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.9194, Accuracy: 7702/10000 (77%)\n",
            "\n",
            "Train Epoch: 2 [0/12000 (0%)]\tLoss: 1.245226\n",
            "Train Epoch: 2 [640/12000 (5%)]\tLoss: 1.241017\n",
            "Train Epoch: 2 [1280/12000 (11%)]\tLoss: 1.429889\n",
            "Train Epoch: 2 [1920/12000 (16%)]\tLoss: 1.126313\n",
            "Train Epoch: 2 [2560/12000 (21%)]\tLoss: 1.247316\n",
            "Train Epoch: 2 [3200/12000 (27%)]\tLoss: 1.217231\n",
            "Train Epoch: 2 [3840/12000 (32%)]\tLoss: 1.258195\n",
            "Train Epoch: 2 [4480/12000 (37%)]\tLoss: 0.844204\n",
            "Train Epoch: 2 [5120/12000 (43%)]\tLoss: 1.103262\n",
            "Train Epoch: 2 [5760/12000 (48%)]\tLoss: 0.743715\n",
            "Train Epoch: 2 [6400/12000 (53%)]\tLoss: 1.010372\n",
            "Train Epoch: 2 [7040/12000 (59%)]\tLoss: 0.816469\n",
            "Train Epoch: 2 [7680/12000 (64%)]\tLoss: 0.943020\n",
            "Train Epoch: 2 [8320/12000 (69%)]\tLoss: 0.927767\n",
            "Train Epoch: 2 [8960/12000 (74%)]\tLoss: 0.783610\n",
            "Train Epoch: 2 [9600/12000 (80%)]\tLoss: 0.786202\n",
            "Train Epoch: 2 [10240/12000 (85%)]\tLoss: 0.744489\n",
            "Train Epoch: 2 [10880/12000 (90%)]\tLoss: 0.865050\n",
            "Train Epoch: 2 [11520/12000 (96%)]\tLoss: 0.735474\n",
            "\n",
            "Test set: Avg. loss: 0.4057, Accuracy: 8900/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 [0/12000 (0%)]\tLoss: 0.609898\n",
            "Train Epoch: 3 [640/12000 (5%)]\tLoss: 1.036952\n",
            "Train Epoch: 3 [1280/12000 (11%)]\tLoss: 0.648704\n",
            "Train Epoch: 3 [1920/12000 (16%)]\tLoss: 0.623525\n",
            "Train Epoch: 3 [2560/12000 (21%)]\tLoss: 0.726515\n",
            "Train Epoch: 3 [3200/12000 (27%)]\tLoss: 0.584570\n",
            "Train Epoch: 3 [3840/12000 (32%)]\tLoss: 1.075651\n",
            "Train Epoch: 3 [4480/12000 (37%)]\tLoss: 0.737894\n",
            "Train Epoch: 3 [5120/12000 (43%)]\tLoss: 0.610208\n",
            "Train Epoch: 3 [5760/12000 (48%)]\tLoss: 0.739189\n",
            "Train Epoch: 3 [6400/12000 (53%)]\tLoss: 0.917956\n",
            "Train Epoch: 3 [7040/12000 (59%)]\tLoss: 0.960519\n",
            "Train Epoch: 3 [7680/12000 (64%)]\tLoss: 0.978612\n",
            "Train Epoch: 3 [8320/12000 (69%)]\tLoss: 0.832149\n",
            "Train Epoch: 3 [8960/12000 (74%)]\tLoss: 0.477857\n",
            "Train Epoch: 3 [9600/12000 (80%)]\tLoss: 0.828698\n",
            "Train Epoch: 3 [10240/12000 (85%)]\tLoss: 0.721391\n",
            "Train Epoch: 3 [10880/12000 (90%)]\tLoss: 0.658510\n",
            "Train Epoch: 3 [11520/12000 (96%)]\tLoss: 0.425573\n",
            "\n",
            "Test set: Avg. loss: 0.3163, Accuracy: 9140/10000 (91%)\n",
            "\n",
            "Train Epoch: 4 [0/12000 (0%)]\tLoss: 0.484214\n",
            "Train Epoch: 4 [640/12000 (5%)]\tLoss: 0.452865\n",
            "Train Epoch: 4 [1280/12000 (11%)]\tLoss: 0.546016\n",
            "Train Epoch: 4 [1920/12000 (16%)]\tLoss: 0.523564\n",
            "Train Epoch: 4 [2560/12000 (21%)]\tLoss: 0.513830\n",
            "Train Epoch: 4 [3200/12000 (27%)]\tLoss: 0.727901\n",
            "Train Epoch: 4 [3840/12000 (32%)]\tLoss: 0.375516\n",
            "Train Epoch: 4 [4480/12000 (37%)]\tLoss: 0.662372\n",
            "Train Epoch: 4 [5120/12000 (43%)]\tLoss: 0.715935\n",
            "Train Epoch: 4 [5760/12000 (48%)]\tLoss: 0.874914\n",
            "Train Epoch: 4 [6400/12000 (53%)]\tLoss: 0.742271\n",
            "Train Epoch: 4 [7040/12000 (59%)]\tLoss: 0.665860\n",
            "Train Epoch: 4 [7680/12000 (64%)]\tLoss: 0.556435\n",
            "Train Epoch: 4 [8320/12000 (69%)]\tLoss: 0.727065\n",
            "Train Epoch: 4 [8960/12000 (74%)]\tLoss: 0.509121\n",
            "Train Epoch: 4 [9600/12000 (80%)]\tLoss: 0.484386\n",
            "Train Epoch: 4 [10240/12000 (85%)]\tLoss: 0.491337\n",
            "Train Epoch: 4 [10880/12000 (90%)]\tLoss: 0.307522\n",
            "Train Epoch: 4 [11520/12000 (96%)]\tLoss: 0.595399\n",
            "\n",
            "Test set: Avg. loss: 0.2319, Accuracy: 9366/10000 (94%)\n",
            "\n",
            "Train Epoch: 5 [0/12000 (0%)]\tLoss: 0.501105\n",
            "Train Epoch: 5 [640/12000 (5%)]\tLoss: 0.480639\n",
            "Train Epoch: 5 [1280/12000 (11%)]\tLoss: 0.716943\n",
            "Train Epoch: 5 [1920/12000 (16%)]\tLoss: 0.711617\n",
            "Train Epoch: 5 [2560/12000 (21%)]\tLoss: 0.476292\n",
            "Train Epoch: 5 [3200/12000 (27%)]\tLoss: 0.483565\n",
            "Train Epoch: 5 [3840/12000 (32%)]\tLoss: 0.491711\n",
            "Train Epoch: 5 [4480/12000 (37%)]\tLoss: 0.313350\n",
            "Train Epoch: 5 [5120/12000 (43%)]\tLoss: 0.485580\n",
            "Train Epoch: 5 [5760/12000 (48%)]\tLoss: 0.390725\n",
            "Train Epoch: 5 [6400/12000 (53%)]\tLoss: 0.412195\n",
            "Train Epoch: 5 [7040/12000 (59%)]\tLoss: 0.665484\n",
            "Train Epoch: 5 [7680/12000 (64%)]\tLoss: 0.720659\n",
            "Train Epoch: 5 [8320/12000 (69%)]\tLoss: 0.585225\n",
            "Train Epoch: 5 [8960/12000 (74%)]\tLoss: 0.432565\n",
            "Train Epoch: 5 [9600/12000 (80%)]\tLoss: 0.297139\n",
            "Train Epoch: 5 [10240/12000 (85%)]\tLoss: 0.484053\n",
            "Train Epoch: 5 [10880/12000 (90%)]\tLoss: 0.327006\n",
            "Train Epoch: 5 [11520/12000 (96%)]\tLoss: 0.461424\n",
            "\n",
            "Test set: Avg. loss: 0.2069, Accuracy: 9394/10000 (94%)\n",
            "\n",
            "Train Epoch: 6 [0/12000 (0%)]\tLoss: 0.363865\n",
            "Train Epoch: 6 [640/12000 (5%)]\tLoss: 0.406896\n",
            "Train Epoch: 6 [1280/12000 (11%)]\tLoss: 0.743510\n",
            "Train Epoch: 6 [1920/12000 (16%)]\tLoss: 0.516297\n",
            "Train Epoch: 6 [2560/12000 (21%)]\tLoss: 0.345956\n",
            "Train Epoch: 6 [3200/12000 (27%)]\tLoss: 0.388854\n",
            "Train Epoch: 6 [3840/12000 (32%)]\tLoss: 0.483935\n",
            "Train Epoch: 6 [4480/12000 (37%)]\tLoss: 0.487709\n",
            "Train Epoch: 6 [5120/12000 (43%)]\tLoss: 0.366151\n",
            "Train Epoch: 6 [5760/12000 (48%)]\tLoss: 0.450279\n",
            "Train Epoch: 6 [6400/12000 (53%)]\tLoss: 0.453460\n",
            "Train Epoch: 6 [7040/12000 (59%)]\tLoss: 0.728624\n",
            "Train Epoch: 6 [7680/12000 (64%)]\tLoss: 0.443646\n",
            "Train Epoch: 6 [8320/12000 (69%)]\tLoss: 0.528333\n",
            "Train Epoch: 6 [8960/12000 (74%)]\tLoss: 0.409733\n",
            "Train Epoch: 6 [9600/12000 (80%)]\tLoss: 0.431549\n",
            "Train Epoch: 6 [10240/12000 (85%)]\tLoss: 0.529149\n",
            "Train Epoch: 6 [10880/12000 (90%)]\tLoss: 0.264388\n",
            "Train Epoch: 6 [11520/12000 (96%)]\tLoss: 0.306037\n",
            "\n",
            "Test set: Avg. loss: 0.1695, Accuracy: 9503/10000 (95%)\n",
            "\n",
            "Train Epoch: 7 [0/12000 (0%)]\tLoss: 0.312617\n",
            "Train Epoch: 7 [640/12000 (5%)]\tLoss: 0.427077\n",
            "Train Epoch: 7 [1280/12000 (11%)]\tLoss: 0.460522\n",
            "Train Epoch: 7 [1920/12000 (16%)]\tLoss: 0.433956\n",
            "Train Epoch: 7 [2560/12000 (21%)]\tLoss: 0.266637\n",
            "Train Epoch: 7 [3200/12000 (27%)]\tLoss: 0.321252\n",
            "Train Epoch: 7 [3840/12000 (32%)]\tLoss: 0.363962\n",
            "Train Epoch: 7 [4480/12000 (37%)]\tLoss: 0.401403\n",
            "Train Epoch: 7 [5120/12000 (43%)]\tLoss: 0.401157\n",
            "Train Epoch: 7 [5760/12000 (48%)]\tLoss: 0.354125\n",
            "Train Epoch: 7 [6400/12000 (53%)]\tLoss: 0.618096\n",
            "Train Epoch: 7 [7040/12000 (59%)]\tLoss: 0.219076\n",
            "Train Epoch: 7 [7680/12000 (64%)]\tLoss: 0.500949\n",
            "Train Epoch: 7 [8320/12000 (69%)]\tLoss: 0.342725\n",
            "Train Epoch: 7 [8960/12000 (74%)]\tLoss: 0.348410\n",
            "Train Epoch: 7 [9600/12000 (80%)]\tLoss: 0.401915\n",
            "Train Epoch: 7 [10240/12000 (85%)]\tLoss: 0.424554\n",
            "Train Epoch: 7 [10880/12000 (90%)]\tLoss: 0.412026\n",
            "Train Epoch: 7 [11520/12000 (96%)]\tLoss: 0.314814\n",
            "\n",
            "Test set: Avg. loss: 0.1578, Accuracy: 9513/10000 (95%)\n",
            "\n",
            "Train Epoch: 8 [0/12000 (0%)]\tLoss: 0.411126\n",
            "Train Epoch: 8 [640/12000 (5%)]\tLoss: 0.358371\n",
            "Train Epoch: 8 [1280/12000 (11%)]\tLoss: 0.239382\n",
            "Train Epoch: 8 [1920/12000 (16%)]\tLoss: 0.479318\n",
            "Train Epoch: 8 [2560/12000 (21%)]\tLoss: 0.207603\n",
            "Train Epoch: 8 [3200/12000 (27%)]\tLoss: 0.428996\n",
            "Train Epoch: 8 [3840/12000 (32%)]\tLoss: 0.250467\n",
            "Train Epoch: 8 [4480/12000 (37%)]\tLoss: 0.344829\n",
            "Train Epoch: 8 [5120/12000 (43%)]\tLoss: 0.267753\n",
            "Train Epoch: 8 [5760/12000 (48%)]\tLoss: 0.378775\n",
            "Train Epoch: 8 [6400/12000 (53%)]\tLoss: 0.599780\n",
            "Train Epoch: 8 [7040/12000 (59%)]\tLoss: 0.465930\n",
            "Train Epoch: 8 [7680/12000 (64%)]\tLoss: 0.527390\n",
            "Train Epoch: 8 [8320/12000 (69%)]\tLoss: 0.396470\n",
            "Train Epoch: 8 [8960/12000 (74%)]\tLoss: 0.655544\n",
            "Train Epoch: 8 [9600/12000 (80%)]\tLoss: 0.313727\n",
            "Train Epoch: 8 [10240/12000 (85%)]\tLoss: 0.283314\n",
            "Train Epoch: 8 [10880/12000 (90%)]\tLoss: 0.360169\n",
            "Train Epoch: 8 [11520/12000 (96%)]\tLoss: 0.371894\n",
            "\n",
            "Test set: Avg. loss: 0.1459, Accuracy: 9529/10000 (95%)\n",
            "\n",
            "Train Epoch: 9 [0/12000 (0%)]\tLoss: 0.370775\n",
            "Train Epoch: 9 [640/12000 (5%)]\tLoss: 0.273941\n",
            "Train Epoch: 9 [1280/12000 (11%)]\tLoss: 0.517430\n",
            "Train Epoch: 9 [1920/12000 (16%)]\tLoss: 0.316886\n",
            "Train Epoch: 9 [2560/12000 (21%)]\tLoss: 0.375283\n",
            "Train Epoch: 9 [3200/12000 (27%)]\tLoss: 0.214777\n",
            "Train Epoch: 9 [3840/12000 (32%)]\tLoss: 0.294517\n",
            "Train Epoch: 9 [4480/12000 (37%)]\tLoss: 0.426159\n",
            "Train Epoch: 9 [5120/12000 (43%)]\tLoss: 0.287127\n",
            "Train Epoch: 9 [5760/12000 (48%)]\tLoss: 0.296490\n",
            "Train Epoch: 9 [6400/12000 (53%)]\tLoss: 0.345932\n",
            "Train Epoch: 9 [7040/12000 (59%)]\tLoss: 0.334428\n",
            "Train Epoch: 9 [7680/12000 (64%)]\tLoss: 0.311388\n",
            "Train Epoch: 9 [8320/12000 (69%)]\tLoss: 0.240392\n",
            "Train Epoch: 9 [8960/12000 (74%)]\tLoss: 0.425550\n",
            "Train Epoch: 9 [9600/12000 (80%)]\tLoss: 0.351274\n",
            "Train Epoch: 9 [10240/12000 (85%)]\tLoss: 0.388538\n",
            "Train Epoch: 9 [10880/12000 (90%)]\tLoss: 0.444663\n",
            "Train Epoch: 9 [11520/12000 (96%)]\tLoss: 0.371022\n",
            "\n",
            "Test set: Avg. loss: 0.1331, Accuracy: 9581/10000 (96%)\n",
            "\n",
            "Train Epoch: 10 [0/12000 (0%)]\tLoss: 0.306425\n",
            "Train Epoch: 10 [640/12000 (5%)]\tLoss: 0.295973\n",
            "Train Epoch: 10 [1280/12000 (11%)]\tLoss: 0.242210\n",
            "Train Epoch: 10 [1920/12000 (16%)]\tLoss: 0.240112\n",
            "Train Epoch: 10 [2560/12000 (21%)]\tLoss: 0.205085\n",
            "Train Epoch: 10 [3200/12000 (27%)]\tLoss: 0.519720\n",
            "Train Epoch: 10 [3840/12000 (32%)]\tLoss: 0.455471\n",
            "Train Epoch: 10 [4480/12000 (37%)]\tLoss: 0.259327\n",
            "Train Epoch: 10 [5120/12000 (43%)]\tLoss: 0.267151\n",
            "Train Epoch: 10 [5760/12000 (48%)]\tLoss: 0.288668\n",
            "Train Epoch: 10 [6400/12000 (53%)]\tLoss: 0.316424\n",
            "Train Epoch: 10 [7040/12000 (59%)]\tLoss: 0.298326\n",
            "Train Epoch: 10 [7680/12000 (64%)]\tLoss: 0.275663\n",
            "Train Epoch: 10 [8320/12000 (69%)]\tLoss: 0.320899\n",
            "Train Epoch: 10 [8960/12000 (74%)]\tLoss: 0.384967\n",
            "Train Epoch: 10 [9600/12000 (80%)]\tLoss: 0.337136\n",
            "Train Epoch: 10 [10240/12000 (85%)]\tLoss: 0.391575\n",
            "Train Epoch: 10 [10880/12000 (90%)]\tLoss: 0.231923\n",
            "Train Epoch: 10 [11520/12000 (96%)]\tLoss: 0.294760\n",
            "\n",
            "Test set: Avg. loss: 0.1293, Accuracy: 9588/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFC0z8-Cv0Eq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b51f48e8-2cd8-4e19-ffc3-ab1223f88be9"
      },
      "source": [
        "# fixing the shape issue\n",
        "print(n_epochs)\n",
        "len(test_losses)\n",
        "\n",
        "len(test_counter)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0b8qoSFhDFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4265e10b-2c5e-4541-c9e4-c10d899f9024"
      },
      "source": [
        "with torch.no_grad():\n",
        "  output = network(example_data)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stlv-UGhohtj",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Accuracy and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NarPid42hIzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "4aed7732-c0ee-4a5e-8c2d-7d8ac573605a"
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Prediction: {}\".format(\n",
        "    output.data.max(1, keepdim=True)[1][i].item()))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}