{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4f_MMOE.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPpbZHIzcVY4PRaFZbgaszG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/AdvanceDeeplearning-CMPE-297/blob/master/Practice/Assignment_4f_MMOE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_fgz39AJ6jL"
      },
      "source": [
        "# Multi-gate Mixture-of-Experts(MMOE)- Using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fir3UgdJQUVT"
      },
      "source": [
        "## Import Libaries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDLBVyscLEVI",
        "outputId": "4939e6ec-b7a8-4497-984e-f77ace0a1cfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.15.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.4`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ0uZI2dLPwn",
        "outputId": "c1837aba-30f0-499d-bc97-c98f5f66a682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mePSw0BlJofz",
        "outputId": "cdb42c19-1221-4cf2-ae61-68e60c61ff2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axu2qrB-KIXN"
      },
      "source": [
        "## MMOE Model- Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L9pu8-nKG4f"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import activations, initializers, regularizers, constraints\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "\n",
        "\n",
        "class MMoE(Layer):\n",
        "    \"\"\"\n",
        "    Multi-gate Mixture-of-Experts model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 units,\n",
        "                 num_experts,\n",
        "                 num_tasks,\n",
        "                 use_expert_bias=True,\n",
        "                 use_gate_bias=True,\n",
        "                 expert_activation='relu',\n",
        "                 gate_activation='softmax',\n",
        "                 expert_bias_initializer='zeros',\n",
        "                 gate_bias_initializer='zeros',\n",
        "                 expert_bias_regularizer=None,\n",
        "                 gate_bias_regularizer=None,\n",
        "                 expert_bias_constraint=None,\n",
        "                 gate_bias_constraint=None,\n",
        "                 expert_kernel_initializer='VarianceScaling',\n",
        "                 gate_kernel_initializer='VarianceScaling',\n",
        "                 expert_kernel_regularizer=None,\n",
        "                 gate_kernel_regularizer=None,\n",
        "                 expert_kernel_constraint=None,\n",
        "                 gate_kernel_constraint=None,\n",
        "                 activity_regularizer=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "         Method for instantiating MMoE layer.\n",
        "        :param units: Number of hidden units\n",
        "        :param num_experts: Number of experts\n",
        "        :param num_tasks: Number of tasks\n",
        "        :param use_expert_bias: Boolean to indicate the usage of bias in the expert weights\n",
        "        :param use_gate_bias: Boolean to indicate the usage of bias in the gate weights\n",
        "        :param expert_activation: Activation function of the expert weights\n",
        "        :param gate_activation: Activation function of the gate weights\n",
        "        :param expert_bias_initializer: Initializer for the expert bias\n",
        "        :param gate_bias_initializer: Initializer for the gate bias\n",
        "        :param expert_bias_regularizer: Regularizer for the expert bias\n",
        "        :param gate_bias_regularizer: Regularizer for the gate bias\n",
        "        :param expert_bias_constraint: Constraint for the expert bias\n",
        "        :param gate_bias_constraint: Constraint for the gate bias\n",
        "        :param expert_kernel_initializer: Initializer for the expert weights\n",
        "        :param gate_kernel_initializer: Initializer for the gate weights\n",
        "        :param expert_kernel_regularizer: Regularizer for the expert weights\n",
        "        :param gate_kernel_regularizer: Regularizer for the gate weights\n",
        "        :param expert_kernel_constraint: Constraint for the expert weights\n",
        "        :param gate_kernel_constraint: Constraint for the gate weights\n",
        "        :param activity_regularizer: Regularizer for the activity\n",
        "        :param kwargs: Additional keyword arguments for the Layer class\n",
        "        \"\"\"\n",
        "        # Hidden nodes parameter\n",
        "        self.units = units\n",
        "        self.num_experts = num_experts\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Weight parameter\n",
        "        self.expert_kernels = None\n",
        "        self.gate_kernels = None\n",
        "        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n",
        "        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n",
        "        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n",
        "        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n",
        "        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n",
        "        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n",
        "\n",
        "        # Activation parameter\n",
        "        self.expert_activation = activations.get(expert_activation)\n",
        "        self.gate_activation = activations.get(gate_activation)\n",
        "\n",
        "        # Bias parameter\n",
        "        self.expert_bias = None\n",
        "        self.gate_bias = None\n",
        "        self.use_expert_bias = use_expert_bias\n",
        "        self.use_gate_bias = use_gate_bias\n",
        "        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n",
        "        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n",
        "        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n",
        "        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n",
        "        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n",
        "        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n",
        "\n",
        "        # Activity parameter\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        # Keras parameter\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.supports_masking = True\n",
        "\n",
        "        super(MMoE, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for creating the layer weights.\n",
        "        :param input_shape: Keras tensor (future input to layer)\n",
        "                            or list/tuple of Keras tensors to reference\n",
        "                            for weight shape computations\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        input_dimension = input_shape[-1]\n",
        "\n",
        "        # Initialize expert weights (number of input features * number of units per expert * number of experts)\n",
        "        self.expert_kernels = self.add_weight(\n",
        "            name='expert_kernel',\n",
        "            shape=(input_dimension, self.units, self.num_experts),\n",
        "            initializer=self.expert_kernel_initializer,\n",
        "            regularizer=self.expert_kernel_regularizer,\n",
        "            constraint=self.expert_kernel_constraint,\n",
        "        )\n",
        "\n",
        "        # Initialize expert bias (number of units per expert * number of experts)\n",
        "        if self.use_expert_bias:\n",
        "            self.expert_bias = self.add_weight(\n",
        "                name='expert_bias',\n",
        "                shape=(self.units, self.num_experts),\n",
        "                initializer=self.expert_bias_initializer,\n",
        "                regularizer=self.expert_bias_regularizer,\n",
        "                constraint=self.expert_bias_constraint,\n",
        "            )\n",
        "\n",
        "        # Initialize gate weights (number of input features * number of experts * number of tasks)\n",
        "        self.gate_kernels = [self.add_weight(\n",
        "            name='gate_kernel_task_{}'.format(i),\n",
        "            shape=(input_dimension, self.num_experts),\n",
        "            initializer=self.gate_kernel_initializer,\n",
        "            regularizer=self.gate_kernel_regularizer,\n",
        "            constraint=self.gate_kernel_constraint\n",
        "        ) for i in range(self.num_tasks)]\n",
        "\n",
        "        # Initialize gate bias (number of experts * number of tasks)\n",
        "        if self.use_gate_bias:\n",
        "            self.gate_bias = [self.add_weight(\n",
        "                name='gate_bias_task_{}'.format(i),\n",
        "                shape=(self.num_experts,),\n",
        "                initializer=self.gate_bias_initializer,\n",
        "                regularizer=self.gate_bias_regularizer,\n",
        "                constraint=self.gate_bias_constraint\n",
        "            ) for i in range(self.num_tasks)]\n",
        "\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dimension})\n",
        "\n",
        "        super(MMoE, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        Method for the forward function of the layer.\n",
        "        :param inputs: Input tensor\n",
        "        :param kwargs: Additional keyword arguments for the base method\n",
        "        :return: A tensor\n",
        "        \"\"\"\n",
        "        gate_outputs = []\n",
        "        final_outputs = []\n",
        "\n",
        "        # f_{i}(x) = activation(W_{i} * x + b), where activation is ReLU according to the paper\n",
        "        expert_outputs = K.tf.tensordot(a=inputs, b=self.expert_kernels, axes=1)\n",
        "        # Add the bias term to the expert weights if necessary\n",
        "        if self.use_expert_bias:\n",
        "            expert_outputs = K.bias_add(x=expert_outputs, bias=self.expert_bias)\n",
        "        expert_outputs = self.expert_activation(expert_outputs)\n",
        "\n",
        "        # g^{k}(x) = activation(W_{gk} * x + b), where activation is softmax according to the paper\n",
        "        for index, gate_kernel in enumerate(self.gate_kernels):\n",
        "            gate_output = K.dot(x=inputs, y=gate_kernel)\n",
        "            # Add the bias term to the gate weights if necessary\n",
        "            if self.use_gate_bias:\n",
        "                gate_output = K.bias_add(x=gate_output, bias=self.gate_bias[index])\n",
        "            gate_output = self.gate_activation(gate_output)\n",
        "            gate_outputs.append(gate_output)\n",
        "\n",
        "        # f^{k}(x) = sum_{i=1}^{n}(g^{k}(x)_{i} * f_{i}(x))\n",
        "        for gate_output in gate_outputs:\n",
        "            expanded_gate_output = K.expand_dims(gate_output, axis=1)\n",
        "            weighted_expert_output = expert_outputs * K.repeat_elements(expanded_gate_output, self.units, axis=1)\n",
        "            final_outputs.append(K.sum(weighted_expert_output, axis=2))\n",
        "\n",
        "        return final_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for computing the output shape of the MMoE layer.\n",
        "        :param input_shape: Shape tuple (tuple of integers)\n",
        "        :return: List of input shape tuple where the size of the list is equal to the number of tasks\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] = self.units\n",
        "        output_shape = tuple(output_shape)\n",
        "\n",
        "        return [output_shape for _ in range(self.num_tasks)]\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Method for returning the configuration of the MMoE layer.\n",
        "        :return: Config dictionary\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'num_experts': self.num_experts,\n",
        "            'num_tasks': self.num_tasks,\n",
        "            'use_expert_bias': self.use_expert_bias,\n",
        "            'use_gate_bias': self.use_gate_bias,\n",
        "            'expert_activation': activations.serialize(self.expert_activation),\n",
        "            'gate_activation': activations.serialize(self.gate_activation),\n",
        "            'expert_bias_initializer': initializers.serialize(self.expert_bias_initializer),\n",
        "            'gate_bias_initializer': initializers.serialize(self.gate_bias_initializer),\n",
        "            'expert_bias_regularizer': regularizers.serialize(self.expert_bias_regularizer),\n",
        "            'gate_bias_regularizer': regularizers.serialize(self.gate_bias_regularizer),\n",
        "            'expert_bias_constraint': constraints.serialize(self.expert_bias_constraint),\n",
        "            'gate_bias_constraint': constraints.serialize(self.gate_bias_constraint),\n",
        "            'expert_kernel_initializer': initializers.serialize(self.expert_kernel_initializer),\n",
        "            'gate_kernel_initializer': initializers.serialize(self.gate_kernel_initializer),\n",
        "            'expert_kernel_regularizer': regularizers.serialize(self.expert_kernel_regularizer),\n",
        "            'gate_kernel_regularizer': regularizers.serialize(self.gate_kernel_regularizer),\n",
        "            'expert_kernel_constraint': constraints.serialize(self.expert_kernel_constraint),\n",
        "            'gate_kernel_constraint': constraints.serialize(self.gate_kernel_constraint),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer)\n",
        "        }\n",
        "        base_config = super(MMoE, self).get_config()\n",
        "\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIUnC-ROKU9e"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icVx9kLsKYi3"
      },
      "source": [
        "\n",
        "   \n",
        "\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "# Fix numpy seed for reproducibility\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "random.seed(SEED)\n",
        "\n",
        "# Fix TensorFlow graph-level seed for reproducibility\n",
        "tf.set_random_seed(SEED)\n",
        "#tf.random.set_seed(SEED)\n",
        "tf_session = tf.Session(graph=tf.get_default_graph())\n",
        "K.set_session(tf_session)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwYCTnQ9Lrb3"
      },
      "source": [
        "## ROCCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D77ape39Lokh"
      },
      "source": [
        "# Simple callback to print out ROC-AUC\n",
        "class ROCCallback(Callback):\n",
        "    def __init__(self, training_data, validation_data, test_data):\n",
        "        self.train_X = training_data[0]\n",
        "        self.train_Y = training_data[1]\n",
        "        self.validation_X = validation_data[0]\n",
        "        self.validation_Y = validation_data[1]\n",
        "        self.test_X = test_data[0]\n",
        "        self.test_Y = test_data[1]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        train_prediction = self.model.predict(self.train_X)\n",
        "        validation_prediction = self.model.predict(self.validation_X)\n",
        "        test_prediction = self.model.predict(self.test_X)\n",
        "\n",
        "        # Iterate through each task and output their ROC-AUC across different datasets\n",
        "        for index, output_name in enumerate(self.model.output_names):\n",
        "            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n",
        "            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n",
        "            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n",
        "            print(\n",
        "                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n",
        "                    output_name, round(train_roc_auc, 4),\n",
        "                    output_name, round(validation_roc_auc, 4),\n",
        "                    output_name, round(test_roc_auc, 4)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "\n",
        "def data_preparation():\n",
        "    # The column names are from\n",
        "    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n",
        "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
        "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
        "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
        "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
        "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
        "\n",
        "    # Load the dataset in Pandas\n",
        "    train_df = pd.read_csv(\n",
        "        'https://github.com/drawbridge/keras-mmoe/blob/master/data/census-income.data.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "    other_df = pd.read_csv(\n",
        "        'https://github.com/drawbridge/keras-mmoe/blob/master/data/census-income.test.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "\n",
        "    # First group of tasks according to the paper\n",
        "    label_columns = ['income_50k', 'marital_stat']\n",
        "\n",
        "    # One-hot encoding categorical columns\n",
        "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
        "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
        "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
        "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                           'vet_question']\n",
        "    train_raw_labels = train_df[label_columns]\n",
        "    other_raw_labels = other_df[label_columns]\n",
        "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "\n",
        "    # Filling the missing column in the other set\n",
        "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
        "\n",
        "    # One-hot encoding categorical labels\n",
        "    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "\n",
        "    dict_outputs = {\n",
        "        'income': train_income.shape[1],\n",
        "        'marital': train_marital.shape[1]\n",
        "    }\n",
        "    dict_train_labels = {\n",
        "        'income': train_income,\n",
        "        'marital': train_marital\n",
        "    }\n",
        "    dict_other_labels = {\n",
        "        'income': other_income,\n",
        "        'marital': other_marital\n",
        "    }\n",
        "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
        "\n",
        "    # Split the other dataset into 1:1 validation to test according to the paper\n",
        "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n",
        "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
        "    validation_data = transformed_other.iloc[validation_indices]\n",
        "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    test_data = transformed_other.iloc[test_indices]\n",
        "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    train_data = transformed_train\n",
        "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
        "\n",
        "    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7BeD33RL0LG"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyIV6hrzLzbe"
      },
      "source": [
        "def main():\n",
        "    # Load the data\n",
        "    train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n",
        "    num_features = train_data.shape[1]\n",
        "\n",
        "    print('Training data shape = {}'.format(train_data.shape))\n",
        "    print('Validation data shape = {}'.format(validation_data.shape))\n",
        "    print('Test data shape = {}'.format(test_data.shape))\n",
        "\n",
        "    # Set up the input layer\n",
        "    input_layer = Input(shape=(num_features,))\n",
        "\n",
        "    # Set up MMoE layer\n",
        "    mmoe_layers = MMoE(\n",
        "        units=4,\n",
        "        num_experts=8,\n",
        "        num_tasks=2\n",
        "    )(input_layer)\n",
        "\n",
        "    output_layers = []\n",
        "\n",
        "    # Build tower layer from MMoE layer\n",
        "    for index, task_layer in enumerate(mmoe_layers):\n",
        "        tower_layer = Dense(\n",
        "            units=8,\n",
        "            activation='relu',\n",
        "            kernel_initializer=VarianceScaling())(task_layer)\n",
        "        output_layer = Dense(\n",
        "            units=output_info[index][0],\n",
        "            name=output_info[index][1],\n",
        "            activation='softmax',\n",
        "            kernel_initializer=VarianceScaling())(tower_layer)\n",
        "        output_layers.append(output_layer)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=[input_layer], outputs=output_layers)\n",
        "    adam_optimizer = Adam()\n",
        "    model.compile(\n",
        "        loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n",
        "        optimizer=adam_optimizer,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Print out model architecture summary\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x=train_data,\n",
        "        y=train_label,\n",
        "        validation_data=(validation_data, validation_label),\n",
        "        callbacks=[\n",
        "            ROCCallback(\n",
        "                training_data=(train_data, train_label),\n",
        "                validation_data=(validation_data, validation_label),\n",
        "                test_data=(test_data, test_label)\n",
        "            )\n",
        "        ],\n",
        "        epochs=100\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}